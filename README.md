# ml-papers

## Image Generation

**Diverse facial inpainting guided by exemplars.**<br>
*Wanglong Lu, Hanli Zhao, Xianta Jiang, Xiaogang Jin, Min Wang, Jiankai Lyu, Kaijie Shi.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2202.06358)] 

**Multi-level Latent Space Structuring for Generative Control.**<br>
*ORENKATZIR, VICKY PEREPELOOK, DANI LISCHINSKI, DANIEL COHEN-OR.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2202.05910)] 

**EqGAN : Improving GAN Equilibrium by Raising Spatial Awareness.**<br>
*Jianyuan Wang, Ceyuan Yang, Yinghao Xu, Yujun Shen, Hongdong Li, Bolei Zhou.*<br>
ICML 2021. [[PDF](https://arxiv.org/abs/2112.00718)] [[Project](https://genforce.github.io/eqgan/)] [[Github](https://github.com/genforce/eqgan)] 

**GANformer: Generative Adversarial Transformers.**<br>
*Drew A. Hudson, C. Lawrence Zitnick.*<br>
ICML 2021. [[PDF](https://arxiv.org/abs/2103.01209)] [[Github](https://github.com/dorarad/gansformer)] 

**Projected GANs Converge Faster.**<br>
*Axel Sauer, Kashyap Chitta, Jens Müller, Andreas Geiger.*<br>
NeurIPS 2021. [[PDF](https://arxiv.org/abs/2111.01007)] [[Project](https://sites.google.com/view/projected-gan/)] [[Github](https://github.com/autonomousvision/projected_gan)] 

**ReStyle : A Residual-Based StyleGAN Encoder via Iterative Refinement.**<br>
*Zongze Wu, Yotam Nitzan, Eli Shechtman, Dani Lischinski.*<br>
ICCV 2021. [[PDF](https://arxiv.org/abs/2104.02699)] [[Project](https://yuval-alaluf.github.io/restyle-encoder/)] [[Github](https://github.com/yuval-alaluf/restyle-encoder)]  

**StyleAlign: Analysis and Applications of Aligned StyleGAN Models.**<br>
*Zongze Wu, Yotam Nitzan, Eli Shechtman, Dani Lischinski.*<br>
ICML under review.

**Explaining in Style: Training a GAN to explain a classifier in StyleSpace.**<br>
*Oran Lang, Yossi Gandelsman, Michal Yarom, Yoav Wald, Gal Elidan, Avinatan Hassidim, William T. Freeman, Phillip Isola, Amir Globerson, Michal Irani, Inbar Mosseri.*<br>
ICCV 2021. [[PDF](https://arxiv.org/abs/2104.13369)] [[Project](https://explaining-in-style.github.io/)] [[Github](https://github.com/google/explaining-in-style)] 

**Alias-Free GAN: Alias-Free Generative Adversarial Networks.**<br>
*Tero Karras, Miika Aittala, Samuli Laine, Erik Härkönen, Janne Hellsten, Jaakko Lehtinen, Timo Aila.*<br>
arxiv 2021. [[PDF](https://arxiv.org/abs/2106.12423)] [[Project](https://nvlabs.github.io/alias-free-gan/)] [[Github](https://github.com/NVlabs/alias-free-gan)] [[Rosinality](https://github.com/rosinality/alias-free-gan-pytorch)] 


## Image-to-Image Translation

**GANcraft: Unsupervised 3D Neural Rendering of Minecraft Worlds.**<br>
*Zekun Hao, Arun Mallya, Serge Belongie, Ming-Yu Liu.*<br>
ICCV 2021(Oral). [[PDF](https://arxiv.org/abs/2104.07659)] [[Project](https://nvlabs.github.io/GANcraft/)] [[Github](https://github.com/NVlabs/imaginaire)] 

**Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation.**<br>
*Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav Shapiro, Daniel Cohen-Or.*<br>
CVPR 2021. [[PDF](https://arxiv.org/abs/2008.00951)] [[Project](https://eladrich.github.io/pixel2style2pixel/)] [[Github](https://github.com/eladrich/pixel2style2pixel)] 

**SPatchGAN: A Statistical Feature Based Discriminator for Unsupervised Image-to-Image Translation.**<br>
*Xuning Shao, Weidong Zhang.*<br>
ICCV 2021. [[PDF](https://arxiv.org/abs/2103.16219)] [[Github](https://github.com/NetEase-GameAI/SPatchGAN)] 

**You Only Need Adversarial Supervision for Semantic Image Synthesis.**<br>
*Vadim Sushko, Edgar Schönfeld, Dan Zhang, Juergen Gall, Bernt Schiele, Anna Khoreva.*<br>
ICLR 2021. [[PDF](https://arxiv.org/abs/2012.04781)] [[Github](https://github.com/boschresearch/OASIS)] 

**A U-Net Based Discriminator for Generative Adversarial Networks.**<br>
*Schonfeld, Edgar and Schiele, Bernt and Khoreva, Anna.*<br>
CVPR 2020. [[PDF](https://arxiv.org/abs/2002.12655)] [[Github](https://github.com/boschresearch/unetgan)] 

**Swapping Autoencoder for Deep Image Manipulation.**<br>
*Taesung Park, Jun-Yan Zhu, Oliver Wang, Jingwan Lu, Eli Shechtman, Alexei A. Efros, Richard Zhang.*<br>
NeurIPS 2020. [[PDF](https://arxiv.org/abs/2007.00653)] [[Project](https://taesung.me/SwappingAutoencoder/)] [[Github](https://github.com/taesungp/swapping-autoencoder-pytorch)] [[Rosinality](https://github.com/rosinality/swapping-autoencoder-pytorch)] 

**Unsupervised image-to-image translation method via pre-trained StyleGAN2 network.**<br>
*Jialu Huang, Jing Liao, Sam Kwong.*<br>
arxiv 2020. [[PDF](https://arxiv.org/abs/2010.05713)] [[Github](https://github.com/HideUnderBush/UI2I_via_StyleGAN2)]  
**Improving Shape Deformation in Unsupervised Image-to-Image Translation.**<br>
*Aaron Gokaslan, Vivek Ramanujan, Daniel Ritchie, Kwang In Kim, James Tompkin.*<br>
arxiv 2018. [[PDF](https://arxiv.org/abs/1808.04325)] [[Github](https://github.com/brownvc/ganimorph)] 


## Image Editing

**Exploiting Spatial Dimensions of Latent in GAN for Real-time Image Editing.**<br>
*Hyunsu Kim, Yunjey Choi, Junho Kim, Sungjoo Yoo, Youngjung Uh.*<br>
CVPR 2021. [[PDF](https://arxiv.org/abs/2104.14754)] [[Github](https://github.com/naver-ai/StyleMapGAN)] 


## Neural Radiance Field

**StyleNeRF: A Style-based 3D Aware Generator for High-resolution Image Synthesis.**<br>
*Anonymous.*<br>
ICLR 2022. [[PDF](https://openreview.net/forum?id=iUuzzTMUw9K)] 


**GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis.**<br>
*Schwarz, Katja and Liao, Yiyi and Niemeyer, Michael and Geiger, Andreas*<br>
NeurIPS 2020. [[PDF](https://arxiv.org/abs/2007.02442)] [[Project](https://avg.is.tuebingen.mpg.de/publications/schwarz2020neurips)] [[Github](https://github.com/autonomousvision/graf)] 

## StyleTransfer

**Interactive Video Stylization Using Few-Shot Patch-Based Training.**<br>
*ONDŘEJ TEXLER, DAVID FUTSCHIK, MICHAL KUČERA, ONDŘEJ JAMRIŠKA, and ŠÁRKA SOCHOROVÁ.*<br>
SIGGRAPH 2020. [[PDF](https://ondrejtexler.github.io/res/Texler20-SIG_patch-based_training_main.pdf)] [[Project](https://ondrejtexler.github.io/patch-based_training/)] [[Github](https://github.com/OndrejTexler/Few-Shot-Patch-Based-Training)] 

**ArtCoder: An End-to-end Method for Generating Scanning-robust Stylized QR Codes.**<br>
*Hao Su, Jianwei Niu, Xuefeng Liu, Qingfeng Li, Ji Wan, Mingliang Xu.*<br>
CVPR 2021. [[PDF](https://arxiv.org/abs/2011.07815)] [[Github](https://github.com/SwordHolderSH/ArtCoder)] 

**Q-Art Code: Generating Scanning-robust Art-style QR Codes by Deformable Convolution.**<br>
*Hao Su, Jianwei Niu, Xuefeng Liu, Qingfeng Li, Ji Wan, Mingliang Xu, Tao Ren.*<br>
ACM International Conference on Multimedia 2021. [[PDF](https://dl.acm.org/doi/abs/10.1145/3474085.3475239)] 
## Normalization

**Positional Normalization.**<br>
*Boyi Li, Felix Wu, Kilian Q. Weinberger, Serge Belongie.*<br>
NeurIPS 2019(spotlight). [[PDF](https://arxiv.org/abs/1907.04312)] [[Github](https://github.com/Boyiliee/Positional-Normalization)]  


## Augmentation

**StyleMix: Separating Content and Style for Enhanced Data Augmentation.**<br>
*Minui Hong, Jinwoo Choi, Gunhee Kim.*<br>
CVPR 2021. [[PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_StyleMix_Separating_Content_and_Style_for_Enhanced_Data_Augmentation_CVPR_2021_paper.pdf)] [[Github](https://github.com/alsdml/StyleMix)]


## Convolution

**Convolutional Hough Matching Networks.**<br>
*Juhong Min, Minsu Cho.*<br>
CVPR 2021(oral). [[PDF](https://arxiv.org/abs/2103.16831)] [[Project](http://cvlab.postech.ac.kr/research/CHM)] [[Github](https://github.com/juhongm999/chm)] 


## Vision Transformer

**Patches Are All You Need?**<br>
*Anonymous authors.*<br>
ICLR 2022. [[PDF](https://openreview.net/pdf?id=TVHS5Y4dNvM)] [[Github](https://github.com/tmp-iclr/convmixer)] 


## Model Compression

**GAN Compression: Efficient Architectures for Interactive Conditional GANs.**<br>
*Muyang Li, Ji Lin, Yaoyao Ding, Zhijian Liu, Jun-Yan Zhu, Song Han.*<br>
CVPR 2020. [[PDF](https://arxiv.org/abs/2003.08936)] [[Project](https://hanlab.mit.edu/projects/gancompression)] [[Github](https://github.com/mit-han-lab/gan-compression)]  



## References Collection

**[1] machine learning:** https://github.com/rosinality/ml-papers

**[2] gan-inversion:** https://github.com/weihaox/awesome-gan-inversion

**[3] image-to-image :** https://github.com/lzhbrian/image-to-image-papers, https://github.com/weihaox/awesome-image-translation

**[4] implementations of Generative Adversarial Networks :** https://github.com/POSTECH-CVLab/PyTorch-StudioGAN

**[5] neural rendering :** https://github.com/weihaox/awesome-neural-rendering, https://github.com/yenchenlin/awesome-NeRF

**[6] 3D human body :** https://github.com/3DFaceBody/awesome-3dbody-papers

**[7] Image-Colorization :** https://github.com/MarkMoHR/Awesome-Image-Colorization

## Accepted Papers

**[1] neurips_2021:** https://papers.labml.ai/papers/neurips_2021

**[2] iclr_2022:** https://papers.labml.ai/papers/iclr_2022
